{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size (50000, 784)\n",
      "Validation Size (10000, 784)\n",
      "Test Size (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=1/6., random_state=42)\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], -1))\n",
    "val_X = val_X.reshape((val_X.shape[0], -1))\n",
    "test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "\n",
    "print(\"Train Size\", train_X.shape)\n",
    "print(\"Validation Size\", val_X.shape)\n",
    "print(\"Test Size\", test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest validation accuracy 0.9436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rfcls = RandomForestClassifier(max_depth=700, n_estimators=10)\n",
    "# parameters = {'max_depth':(100, 300, 500, 700, None)}\n",
    "# rfcls = GridSearchCV(rf, parameters)\n",
    "rfcls.fit(train_X, train_y)\n",
    "# print(\"Best parameter\",rfcls.best_params_)\n",
    "\n",
    "prediction = rfcls.predict(val_X)\n",
    "\n",
    "\n",
    "print(\"Random Forest validation accuracy\", accuracy_score(val_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees validation accuracy 0.9507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etcls = ExtraTreesClassifier(n_estimators=10, random_state=42)\n",
    "etcls.fit(train_X, train_y)\n",
    "\n",
    "prediction = etcls.predict(val_X)\n",
    "print(\"Extra Trees validation accuracy\", accuracy_score(val_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adacls = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=10, \n",
    "                            algorithm=\"SAMME.R\", learning_rate=0.8)\n",
    "adacls.fit(train_X, train_y)\n",
    "prediction = adacls.predict(val_X)\n",
    "print(\"Adaboost validation accuracy\", accuracy_score(val_y, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vcls_h = VotingClassifier(estimators=[('random forest', rfcls), ('extra trees', etcls), \n",
    "                                           ('adaviist', adacls)], voting='hard')\n",
    "\n",
    "\n",
    "for clf in (rfcls, etcls, adacls, vcls_h):\n",
    "    clf.fit(train_X, train_y)\n",
    "    prediction = clf.predict(val_X)\n",
    "    print(clf.__class__.__name__, accuracy_score(prediction, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcls_s = VotingClassifier(estimators=[('random forest', rfcls), ('extra trees', etcls), \n",
    "                                           ('adaviist', adacls)], voting='soft')\n",
    "\n",
    "vcls_s.fit(train_X, train_y)\n",
    "prediction = vcls_s.predict(val_X)\n",
    "print(vcls_s.__class__.__name__, accuracy_score(prediction, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9421\n",
      "ExtraTreesClassifier 0.9467\n",
      "AdaBoostClassifier 0.9414\n",
      "VotingClassifier 0.9549\n",
      "VotingClassifier 0.9523\n"
     ]
    }
   ],
   "source": [
    "for clf in (rfcls, etcls, adacls, vcls_h, vcls_s):\n",
    "    prediction = clf.predict(test_X)\n",
    "    print(clf.__class__.__name__, accuracy_score(prediction, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model: Hard Voting Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
